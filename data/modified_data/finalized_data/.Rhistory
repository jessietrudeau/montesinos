select(n, date, speakers, num_speakers, all_of(topic_columns)) %>%
pivot_longer(cols = all_of(topic_columns), names_to = "topic", values_to = "present") %>%
filter(!is.na(present)) %>%
mutate(topic = gsub("topic_", "", topic))  # Remove "topic_" prefix for clarity
# Load required packages
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(vistime)
library(lubridate)
library(stringr)  # For counting speakers
# Read the TSV file
file_path <- "C:/Users/agsotopl/Downloads/Copy of inventory - Transcript inventory.tsv"
data <- read_tsv(file_path)
# Convert 'date' column to Date format
data <- data %>%
mutate(date = mdy(date)) %>%
filter(!is.na(date))
# Count number of speakers
data <- data %>%
mutate(num_speakers = ifelse(is.na(speakers), 0, str_count(speakers, ",") + 1))
# Select topic columns and reshape into long format
topic_columns <- names(data)[grepl("^topic_", names(data))]
long_data <- data %>%
select(n, date, speakers, num_speakers, all_of(topic_columns)) %>%
pivot_longer(cols = all_of(topic_columns), names_to = "topic", values_to = "present") %>%
filter(!is.na(present)) %>%
mutate(topic = gsub("topic_", "", topic))  # Remove "topic_" prefix for clarity
# Define a custom gradient with multiple breakpoints
ggplot(long_data, aes(x = date, y = topic, color = num_speakers)) +
geom_point(size = 3, alpha = 0.8) +
scale_color_gradientn(colors = c("blue", "green", "yellow", "orange", "red"),
values = scales::rescale(c(min(long_data$num_speakers, na.rm = TRUE),
quantile(long_data$num_speakers, 0.25, na.rm = TRUE),
median(long_data$num_speakers, na.rm = TRUE),
quantile(long_data$num_speakers, 0.75, na.rm = TRUE),
max(long_data$num_speakers, na.rm = TRUE)))) +
scale_x_date(date_breaks = "5 years", date_labels = "%Y") +
labs(title = "Timeline of Conversations by Topic",
subtitle = "Based on transcript inventory",
x = "Date",
y = "Topic",
color = "Number of Speakers") +
theme_minimal()
# Load required packages
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(vistime)
library(lubridate)
library(stringr)  # For counting speakers
# Read the TSV file
file_path <- "C:/Users/agsotopl/Downloads/Copy of inventory - Transcript inventory.tsv"
data <- read_tsv(file_path)
# Convert 'date' column to Date format
data <- data %>%
mutate(date = mdy(date)) %>%
filter(!is.na(date))
# Count number of speakers
data <- data %>%
mutate(num_speakers = ifelse(is.na(speakers), 0, str_count(speakers, ",") + 1))
# Select topic columns and reshape into long format
topic_columns <- names(data)[grepl("^topic_", names(data))]
long_data <- data %>%
select(n, date, speakers, num_speakers, all_of(topic_columns)) %>%
pivot_longer(cols = all_of(topic_columns), names_to = "topic", values_to = "present") %>%
filter(!is.na(present)) %>%
mutate(topic = gsub("topic_", "", topic))  # Remove "topic_" prefix for clarity
# Define a custom gradient with multiple breakpoints
ggplot(long_data, aes(x = date, y = topic, color = num_speakers)) +
geom_point(size = 3, alpha = 0.8) +
scale_color_gradientn(colors = c("blue", "skyblue", "yellow", "lightgreen", "seagreen"),
values = scales::rescale(c(min(long_data$num_speakers, na.rm = TRUE),
quantile(long_data$num_speakers, 0.25, na.rm = TRUE),
median(long_data$num_speakers, na.rm = TRUE),
quantile(long_data$num_speakers, 0.75, na.rm = TRUE),
max(long_data$num_speakers, na.rm = TRUE)))) +
scale_x_date(date_breaks = "5 years", date_labels = "%Y") +
labs(title = "Timeline of Conversations by Topic",
subtitle = "Based on transcript inventory",
x = "Date",
y = "Topic",
color = "Number of Speakers") +
theme_minimal()
setwd<-"C:/Users/agsotopl/Downloads/montesinos"
file<-"C:/Users/agsotopl/Downloads/Copy of Master - transcript notes - Actors.csv"
df<-read_csv(file)
View(df)
# Import file
setwd<-"C:/Users/agsotopl/Downloads/montesinos"
file<-"C:/Users/agsotopl/Downloads/Copy of Master - transcript notes - Actors.csv"
df<-read_csv(file)
View(df)
df["Type_Merged"] = df.apply(lambda row: "Inner Circle" if row["Montesinos' inner circle"] == "X" else row["Type"], axis=1)
# Merge "Type" and "Montesinos' inner circle" columns with prioritization of inner circle
df["Type_Merged"] = df.apply(
lambda row: "Inner Circle" if row["Montesinos' inner circle"] == "X" else row["Type"], axis=1
# Merge 'Type' and 'Montesinos_inner_circle' columns
df$Type_Merged <- ifelse(df$Montesinos.inner.circle == "X", "Inner Circle", df$Type)
colnames(df)
colnames(df) <- gsub(" ", "_", colnames(df))   # Replace spaces with underscores
colnames(df) <- gsub("'", "", colnames(df))    # Remove apostrophes
# Check if renaming worked
colnames(df)
# Merge Type and Montesinos_inner_circle column
df$Type_Merged <- ifelse(df$Montesinos_inner_circle == "X", "Inner Circle", df$Type)
head(df)
View(df)
# Ensure column names are accessible
colnames(df) <- gsub(" ", "_", colnames(df))   # Replace spaces with underscores
colnames(df) <- gsub("'", "", colnames(df))    # Remove apostrophes
# Fix: Replace "Type" only if the "Montesinos_inner_circle" column contains "X"
df$Type_Merged <- ifelse(df$Montesinos_inner_circle == "X", "Inner Circle", df$Type)
# Verify the result
head(df[, c("Type", "Montesinos_inner_circle", "Type_Merged")])
# Ensure column names are clean
colnames(df) <- gsub(" ", "_", colnames(df))   # Replace spaces with underscores
colnames(df) <- gsub("'", "", colnames(df))    # Remove apostrophes
# Fix NA values: Ensure we replace only when necessary
df$Type_Merged <- ifelse(!is.na(df$Montesinos_inner_circle) & df$Montesinos_inner_circle == "X",
"Inner Circle",
ifelse(!is.na(df$Type), df$Type, NA))
# Verify the result
head(df[, c("Type", "Montesinos_inner_circle", "Type_Merged")])
# Create a summary table counting the occurrences of each unique value in "Type_Merged"
type_summary = df["Type_Merged"].value_counts().reset_index()
# Create a summary table counting occurrences of each unique value in "Type_Merged"
type_summary <- df %>%
group_by(Type_Merged) %>%
summarise(Count = n(), .groups = "drop") %>%
arrange(desc(Count))
# Print summary table
print(type_summary)
# Load necessary libraries
library(dplyr)
library(readr)
library(stringr)
# Set directory containing transcript files
directory <- "C:/Users/agsotopl/Downloads/montesinos/data/modified_data/finalized_data"
# Load the Master-transcript file
master_transcript <- read_csv("C:/Users/agsotopl/Downloads/Copy of Master - transcript notes - Actors.csv")  # Change file path
# Extract standardized speaker names
speakers <- unique(master_transcript$speaker_std)
# Initialize an empty data frame to store speaker counts
speaker_counts <- data.frame(speaker_std = speakers, count = 0, stringsAsFactors = FALSE)
# List all CSV and TSV files in the directory
file_list <- list.files(directory, pattern = "\.(csv|tsv)$", full.names = TRUE)
# Load necessary libraries
library(dplyr)
library(readr)
library(stringr)
# Set directory containing transcript files
directory <- "C:/Users/agsotopl/Downloads/montesinos/data/modified_data/finalized_data"
# Load the Master-transcript file
master_transcript <- read_csv("C:/Users/agsotopl/Downloads/Copy of Master - transcript notes - Actors.csv")  # Change file path
# Extract standardized speaker names
speakers <- unique(master_transcript$speaker_std)
# Initialize an empty data frame to store speaker counts
speaker_counts <- data.frame(speaker_std = speakers, count = 0, stringsAsFactors = FALSE)
# List all CSV and TSV files in the directory
file_list <- list.files(directory, pattern = "\\\\.(csv|tsv)$", full.names = TRUE)
# Function to count speaker occurrences in a single file
count_speakers <- function(file_path) {
# Detect delimiter
delimiter <- ifelse(grepl(".csv$", file_path), ",", "\t")
# Read file
data <- read_delim(file_path, delim = delimiter, col_types = cols(.default = "c"))
# Ensure the "speaker_std" column exists
if (!"speaker_std" %in% colnames(data)) return(NULL)
# Count occurrences of each speaker in this file
counts <- data %>%
filter(speaker_std %in% speakers) %>%
count(speaker_std)
return(counts)
}
# Iterate over all files and update counts
for (file in file_list) {
file_counts <- count_speakers(file)
if (!is.null(file_counts)) {
# Merge counts with the master speaker count table
speaker_counts <- speaker_counts %>%
left_join(file_counts, by = "speaker_std", suffix = c("", "_new")) %>%
mutate(count = count + replace_na(n, 0)) %>%
select(-n)
}
}
# Save the results to a CSV file
write_csv(speaker_counts, "speaker_occurrences_summary.csv")
# Print results
print(speaker_counts)
View(df)
speaker_counts$speaker_std
View(df)
# Load necessary libraries
install.packages("stringi")
library(dplyr)
library(readr)
library(stringr)
library(stringi)
# Set directory containing transcript files
directory <- "C:/Users/agsotopl/Downloads/montesinos/data/modified_data/finalized_data"
# Load the Master-transcript file
master_transcript <- read_csv("C:/Users/agsotopl/Downloads/Copy of Master - transcript notes - Actors.csv")  # Change file path
# Function to standardize speaker names
standardize_speaker <- function(name) {
name %>%
str_squish() %>%  # Remove extra spaces
str_to_upper() %>% # Convert to uppercase
stri_trans_general("Latin-ASCII") # Remove accents and special characters
}
# Extract standardized speaker names
master_transcript <- master_transcript %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
speakers <- unique(master_transcript$speaker_std)
# Print sample speakers for debugging
message("Sample speakers from Master-transcript:")
print(sample(speakers, 5))
# Initialize an empty data frame to store speaker counts
speaker_counts <- data.frame(speaker_std = speakers, count = 0, stringsAsFactors = FALSE)
# List all CSV and TSV files in the directory
file_list <- list.files(directory, pattern = "\\.(csv|tsv)$", full.names = TRUE)
# Function to count speaker occurrences in a single file
count_speakers <- function(file_path) {
# Detect delimiter
delimiter <- ifelse(grepl(".csv$", file_path), ",", "\t")
# Read file
data <- read_delim(file_path, delim = delimiter, col_types = cols(.default = "c"))
# Ensure the "speaker_std" column exists
if (!"speaker_std" %in% colnames(data)) {
message("Skipping file: ", file_path, " (column 'speaker_std' not found)")
return(NULL)
}
# Standardize speaker_std values
data <- data %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
# Print sample speakers from transcript file for debugging
message("Sample speakers from ", file_path, ":")
print(sample(data$speaker_std, 5))
# Identify mismatched speakers for debugging
missing_speakers <- setdiff(data$speaker_std, speakers)
if (length(missing_speakers) > 0) {
message("Warning: Unmatched speaker names found in ", file_path, " (showing first 5): ")
print(head(missing_speakers, 5))
}
# Count occurrences of each speaker in this file
counts <- data %>%
filter(speaker_std %in% speakers) %>%
count(speaker_std)
return(counts)
}
# Iterate over all files and update counts
for (file in file_list) {
file_counts <- count_speakers(file)
if (!is.null(file_counts)) {
# Merge counts with the master speaker count table
speaker_counts <- speaker_counts %>%
left_join(file_counts, by = "speaker_std", suffix = c("", "_new")) %>%
mutate(count = count + replace_na(n, 0)) %>%
select(-n)
}
}
# Save the results to a CSV file
write_csv(speaker_counts, "speaker_occurrences_summary.csv")
# Print results
print(speaker_counts)
# Load necessary libraries
library(dplyr)
library(readr)
library(stringr)
library(stringi) # For text normalization
# Set directory containing transcript files
directory <- "path/to/transcript/files"  # Change this to the correct directory
# Load the Master-transcript file
master_transcript <- read_csv("path/to/Master-transcript.csv")  # Change file path
library(dplyr)
library(readr)
library(stringr)
library(stringi)
# Set directory containing transcript files
directory <- "C:/Users/agsotopl/Downloads/montesinos/data/modified_data/finalized_data"
# Load the Master-transcript file
master_transcript <- read_csv("C:/Users/agsotopl/Downloads/Copy of Master - transcript notes - Actors.csv")  # Change file path
# Function to standardize speaker names
standardize_speaker <- function(name) {
name %>%
str_squish() %>%  # Remove extra spaces
str_to_upper() %>% # Convert to uppercase
stri_trans_general("Latin-ASCII") # Remove accents and special characters
}
# Extract standardized speaker names
master_transcript <- master_transcript %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
speakers <- unique(master_transcript$speaker_std)
# Print sample speakers for debugging
message("Sample speakers from Master-transcript:")
print(sample(speakers, 5))
# Initialize an empty data frame to store transcript counts per speaker
speaker_transcript_counts <- data.frame(speaker_std = speakers, transcript_count = 0, stringsAsFactors = FALSE)
# List all CSV and TSV files in the directory
file_list <- list.files(directory, pattern = "\\.(csv|tsv)$", full.names = TRUE)
# Function to count in how many transcripts each speaker appears
count_speakers_in_transcripts <- function(file_path) {
# Detect delimiter
delimiter <- ifelse(grepl(".csv$", file_path), ",", "\t")
# Read file
data <- read_delim(file_path, delim = delimiter, col_types = cols(.default = "c"))
# Ensure the "speaker_std" column exists
if (!"speaker_std" %in% colnames(data)) {
message("Skipping file: ", file_path, " (column 'speaker_std' not found)")
return(NULL)
}
# Standardize speaker_std values
data <- data %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
# Identify unique speakers in this transcript
unique_speakers <- unique(data$speaker_std[data$speaker_std %in% speakers])
return(data.frame(speaker_std = unique_speakers, present = 1))
}
# Iterate over all files and update transcript counts
all_transcript_counts <- list()
for (file in file_list) {
file_counts <- count_speakers_in_transcripts(file)
if (!is.null(file_counts)) {
all_transcript_counts <- append(all_transcript_counts, list(file_counts))
}
}
library(dplyr)
library(readr)
library(stringr)
library(stringi)
# Set directory containing transcript files
directory <- "C:/Users/agsotopl/Downloads/montesinos/data/modified_data/finalized_data"
# Load the Master-transcript file
master_transcript <- read_csv("C:/Users/agsotopl/Downloads/Copy of Master - transcript notes - Actors.csv")  # Change file path
# Function to standardize speaker names
standardize_speaker <- function(name) {
name %>%
str_squish() %>%  # Remove extra spaces
str_to_upper() %>% # Convert to uppercase
stri_trans_general("Latin-ASCII") # Remove accents and special characters
}
# Extract standardized speaker names
master_transcript <- master_transcript %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
speakers <- unique(master_transcript$speaker_std)
# Print sample speakers for debugging
message("Sample speakers from Master-transcript:")
print(sample(speakers, 5))
# Initialize an empty data frame to store transcript counts per speaker
speaker_transcript_counts <- data.frame(speaker_std = speakers, transcript_count = 0, stringsAsFactors = FALSE)
# List all CSV and TSV files in the directory
file_list <- list.files(directory, pattern = "\\.(csv|tsv)$", full.names = TRUE)
# Function to count in how many transcripts each speaker appears
count_speakers_in_transcripts <- function(file_path) {
# Detect delimiter
delimiter <- ifelse(grepl(".csv$", file_path), ",", "\t")
# Read file
data <- read_delim(file_path, delim = delimiter, col_types = cols(.default = "c"))
# Ensure the "speaker_std" column exists
if (!"speaker_std" %in% colnames(data)) {
message("Skipping file: ", file_path, " (column 'speaker_std' not found)")
return(NULL)
}
# Standardize speaker_std values
data <- data %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
# Identify unique speakers in this transcript
unique_speakers <- unique(data$speaker_std[data$speaker_std %in% speakers])
# Handle empty unique_speakers to avoid errors
if (length(unique_speakers) == 0) {
return(NULL)  # Skip this file if no speakers match
}
return(data.frame(speaker_std = unique_speakers, present = 1, stringsAsFactors = FALSE))
}
# Iterate over all files and update transcript counts
all_transcript_counts <- list()
for (file in file_list) {
file_counts <- count_speakers_in_transcripts(file)
if (!is.null(file_counts)) {
all_transcript_counts <- append(all_transcript_counts, list(file_counts))
}
}
# Combine results and count occurrences per transcript
if (length(all_transcript_counts) > 0) {
combined_counts <- bind_rows(all_transcript_counts) %>%
group_by(speaker_std) %>%
summarise(transcript_count = n())
# Merge with full speaker list
speaker_transcript_counts <- speaker_transcript_counts %>%
left_join(combined_counts, by = "speaker_std") %>%
mutate(transcript_count = replace_na(transcript_count, 0))
}
# Function to standardize speaker names
standardize_speaker <- function(name) {
name %>%
str_squish() %>%  # Remove extra spaces
str_to_upper() %>% # Convert to uppercase
stri_trans_general("Latin-ASCII") # Remove accents and special characters
}
# Extract standardized speaker names
master_transcript <- master_transcript %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
speakers <- unique(master_transcript$speaker_std)
# Print sample speakers for debugging
message("Sample speakers from Master-transcript:")
print(sample(speakers, 5))
# Initialize an empty data frame to store transcript counts per speaker
speaker_transcript_counts <- data.frame(speaker_std = speakers, transcript_count = 0, stringsAsFactors = FALSE)
# List all CSV and TSV files in the directory
file_list <- list.files(directory, pattern = "\\.(csv|tsv)$", full.names = TRUE)
# Function to count in how many transcripts each speaker appears
count_speakers_in_transcripts <- function(file_path) {
# Detect delimiter
delimiter <- ifelse(grepl(".csv$", file_path), ",", "\t")
# Read file
data <- read_delim(file_path, delim = delimiter, col_types = cols(.default = "c"))
# Ensure the "speaker_std" column exists
if (!"speaker_std" %in% colnames(data)) {
message("Skipping file: ", file_path, " (column 'speaker_std' not found)")
return(NULL)
}
# Standardize speaker_std values
data <- data %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
# Identify unique speakers in this transcript
unique_speakers <- unique(data$speaker_std[data$speaker_std %in% speakers])
# Handle empty unique_speakers to avoid errors
if (length(unique_speakers) == 0) {
return(NULL)  # Skip this file if no speakers match
}
return(data.frame(speaker_std = unique_speakers, present = 1, stringsAsFactors = FALSE))
}
# Iterate over all files and update transcript counts
all_transcript_counts <- list()
for (file in file_list) {
file_counts <- count_speakers_in_transcripts(file)
if (!is.null(file_counts)) {
all_transcript_counts <- append(all_transcript_counts, list(file_counts))
}
}
# Combine results and count occurrences per transcript
if (length(all_transcript_counts) > 0) {
combined_counts <- bind_rows(all_transcript_counts) %>%
group_by(speaker_std) %>%
summarise(transcript_count = n(), .groups = "drop")
# Merge with full speaker list, ensuring transcript_count exists
speaker_transcript_counts <- speaker_transcript_counts %>%
left_join(combined_counts, by = "speaker_std") %>%
mutate(transcript_count = coalesce(transcript_count, 0))
}
# Function to standardize speaker names
standardize_speaker <- function(name) {
name %>%
str_squish() %>%  # Remove extra spaces
str_to_upper() %>% # Convert to uppercase
stri_trans_general("Latin-ASCII") # Remove accents and special characters
}
# Extract standardized speaker names
master_transcript <- master_transcript %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
speakers <- unique(master_transcript$speaker_std)
# Print sample speakers for debugging
message("Sample speakers from Master-transcript:")
print(sample(speakers, 5))
# Initialize an empty data frame to store transcript counts per speaker
speaker_transcript_counts <- data.frame(speaker_std = speakers, transcript_count = 0, stringsAsFactors = FALSE)
# List all CSV and TSV files in the directory
file_list <- list.files(directory, pattern = "\\.(csv|tsv)$", full.names = TRUE)
# Function to count in how many transcripts each speaker appears
count_speakers_in_transcripts <- function(file_path) {
# Detect delimiter
delimiter <- ifelse(grepl(".csv$", file_path), ",", "\t")
# Read file
data <- read_delim(file_path, delim = delimiter, col_types = cols(.default = "c"))
# Ensure the "speaker_std" column exists
if (!"speaker_std" %in% colnames(data)) {
message("Skipping file: ", file_path, " (column 'speaker_std' not found)")
return(NULL)
}
# Standardize speaker_std values
data <- data %>%
mutate(speaker_std = as.character(standardize_speaker(speaker_std)))
# Identify unique speakers in this transcript
unique_speakers <- unique(data$speaker_std[data$speaker_std %in% speakers])
# Handle empty unique_speakers to avoid errors
if (length(unique_speakers) == 0) {
return(NULL)  # Skip this file if no speakers match
}
return(data.frame(speaker_std = unique_speakers, present = 1, stringsAsFactors = FALSE))
}
# Iterate over all files and update transcript counts
all_transcript_counts <- list()
for (file in file_list) {
file_counts <- count_speakers_in_transcripts(file)
if (!is.null(file_counts)) {
all_transcript_counts <- append(all_transcript_counts, list(file_counts))
}
}
# Combine results and count occurrences per transcript
if (length(all_transcript_counts) > 0) {
combined_counts <- bind_rows(all_transcript_counts) %>%
group_by(speaker_std) %>%
summarise(transcript_count = n(), .groups = "drop")
} else {
combined_counts <- data.frame(speaker_std = character(), transcript_count = integer(), stringsAsFactors = FALSE)
}
# Merge with full speaker list, ensuring transcript_count exists
speaker_transcript_counts <- speaker_transcript_counts %>%
left_join(combined_counts, by = "speaker_std") %>%
mutate(transcript_count = ifelse(is.na(transcript_count), 0, transcript_count))
